{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35306ad",
   "metadata": {},
   "source": [
    "# Pre Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a92f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyreadstat\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a928acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the output directory\n",
    "\n",
    "output_directory = r\"C:\\Users\\ShindeAnk\\OneDrive - Kantar\\Punit Team\\Training Documents\\BSA Training\\Automation\\BSA Process_Automation\\Output\"\n",
    "output_file = \"output.xlsx\"\n",
    "output_path = os.path.join(output_directory, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9466da2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b788c28a57b4083bf90c95817e4d321",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value={}, accept='.sav', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initializing global DataFrames\n",
    "data_view = pd.DataFrame()\n",
    "variable_view = pd.DataFrame()\n",
    "\n",
    "# Function to handle the file upload and read the data\n",
    "def handle_file_upload(change):\n",
    "    global data_view, variable_view  # Declare global variables\n",
    "\n",
    "    # Access the uploaded file from the widget\n",
    "    uploaded_file = next(iter(change['new'].values()))  # Get the uploaded file content\n",
    "    if uploaded_file:\n",
    "        # Convert the uploaded file to a BytesIO object\n",
    "        file_content = BytesIO(uploaded_file['content'])\n",
    "        \n",
    "        # Write the BytesIO object to a temporary file\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as temp_file:\n",
    "            temp_file.write(file_content.getvalue())\n",
    "            temp_file_path = temp_file.name\n",
    "        \n",
    "        # Load the data and metadata from the temporary file\n",
    "        df, meta = pyreadstat.read_sav(temp_file_path)\n",
    "        \n",
    "        # Function to replace values with labels\n",
    "        def apply_value_labels(data, meta):\n",
    "            for column_name in data.columns:\n",
    "                if column_name in meta.variable_value_labels:\n",
    "                    value_labels = meta.variable_value_labels[column_name]\n",
    "                    data[column_name] = data[column_name].map(value_labels)\n",
    "            return data\n",
    "        \n",
    "        # Apply the value labels to the data\n",
    "        data_view = apply_value_labels(df.copy(), meta)\n",
    "        \n",
    "        # Variable View: metadata about the variables\n",
    "        variable_view = pd.DataFrame({\n",
    "            'Variable Name': meta.column_names,\n",
    "            'Variable Label': meta.column_labels\n",
    "        })\n",
    "        \n",
    "        # Display the head of data_view and variable_view\n",
    "        print(\"Data View after applying value labels:\")\n",
    "        display(data_view.head())\n",
    "        print(\"Variable View:\")\n",
    "        display(variable_view.head(20))\n",
    "\n",
    "# Create the file upload widget\n",
    "upload_widget = widgets.FileUpload(accept='.sav', multiple=False)\n",
    "\n",
    "# Display the widget\n",
    "display(upload_widget)\n",
    "\n",
    "# Attach the event handler to process the file once it's uploaded\n",
    "upload_widget.observe(handle_file_upload, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0371e96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb08ef1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48995ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_view.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b77bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_view.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d696f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary for mapping variable names to labels\n",
    "mapping_dict = variable_view.set_index('Variable Name')['Variable Label'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "652a8c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, mapping_dict):\n",
    "    return df.rename(columns=mapping_dict)\n",
    "\n",
    "# Replace the variable names in the \"UK Category\" DataFrame with the corresponding labels\n",
    "data_view_renamed = rename_columns(data_view, mapping_dict)\n",
    "\n",
    "# Now df_uk_category_renamed has the columns with the actual names from the \"Variable label\" sheet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12ad5eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent_id (KANSOS ID)</th>\n",
       "      <th>Fieldwork country</th>\n",
       "      <th>PersistentRespondentId</th>\n",
       "      <th>Timings_yyyymmdd</th>\n",
       "      <th>Timings_WeekNumber</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month and Year</th>\n",
       "      <th>Weighting variable</th>\n",
       "      <th>...</th>\n",
       "      <th>BEAST - CM_GrpdSegs</th>\n",
       "      <th>BEAST - MarketFactors_SoEUnrealised</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I_202212_BRA_434393844</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220326.0</td>\n",
       "      <td>202212.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>2.5113</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202212_BRA_4343938442022041</td>\n",
       "      <td>I_202212_BRA_434393844</td>\n",
       "      <td>434393844</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I_202212_BRA_464393944</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220327.0</td>\n",
       "      <td>202212.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202212_BRA_4643939442022041</td>\n",
       "      <td>I_202212_BRA_464393944</td>\n",
       "      <td>464393944</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I_202212_BRA_464393946</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220327.0</td>\n",
       "      <td>202212.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202212_BRA_4643939462022041</td>\n",
       "      <td>I_202212_BRA_464393946</td>\n",
       "      <td>464393946</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I_202213_BRA_404084541</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220401.0</td>\n",
       "      <td>202213.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>1.3867</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.435618</td>\n",
       "      <td>I_202213_BRA_4040845412022041</td>\n",
       "      <td>I_202213_BRA_404084541</td>\n",
       "      <td>404084541</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I_202213_BRA_404094948</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220401.0</td>\n",
       "      <td>202213.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>...</td>\n",
       "      <td>Uncommitted</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202213_BRA_4040949482022041</td>\n",
       "      <td>I_202213_BRA_404094948</td>\n",
       "      <td>404094948</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Respondent_id (KANSOS ID) Fieldwork country PersistentRespondentId  \\\n",
       "0    I_202212_BRA_434393844            Brazil                          \n",
       "1    I_202212_BRA_464393944            Brazil                          \n",
       "2    I_202212_BRA_464393946            Brazil                          \n",
       "3    I_202213_BRA_404084541            Brazil                          \n",
       "4    I_202213_BRA_404094948            Brazil                          \n",
       "\n",
       "   Timings_yyyymmdd  Timings_WeekNumber                        Brand  Month  \\\n",
       "0        20220326.0            202212.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "1        20220327.0            202212.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "2        20220327.0            202212.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "3        20220401.0            202213.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "4        20220401.0            202213.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "\n",
       "     Year Month and Year  Weighting variable  ...  BEAST - CM_GrpdSegs  \\\n",
       "0  2022.0     April 2022              2.5113  ...               Steady   \n",
       "1  2022.0     April 2022              0.8579  ...               Steady   \n",
       "2  2022.0     April 2022              0.8579  ...               Steady   \n",
       "3  2022.0     April 2022              1.3867  ...               Steady   \n",
       "4  2022.0     April 2022              0.8464  ...          Uncommitted   \n",
       "\n",
       "   BEAST - MarketFactors_SoEUnrealised                           None  \\\n",
       "0                             0.000000  I_202212_BRA_4343938442022041   \n",
       "1                             0.000000  I_202212_BRA_4643939442022041   \n",
       "2                             0.000000  I_202212_BRA_4643939462022041   \n",
       "3                             0.435618  I_202213_BRA_4040845412022041   \n",
       "4                             0.000000  I_202213_BRA_4040949482022041   \n",
       "\n",
       "                     None       None      None  None  None  None  None  \n",
       "0  I_202212_BRA_434393844  434393844  202204.0   BRA   1.0   0.0  TRUE  \n",
       "1  I_202212_BRA_464393944  464393944  202204.0   BRA   1.0   1.0  TRUE  \n",
       "2  I_202212_BRA_464393946  464393946  202204.0   BRA   1.0   1.0  TRUE  \n",
       "3  I_202213_BRA_404084541  404084541  202204.0   BRA   1.0   0.0  TRUE  \n",
       "4  I_202213_BRA_404094948  404094948  202204.0   BRA   1.0   0.0  TRUE  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_view_renamed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e3add4",
   "metadata": {},
   "source": [
    "##### Apppy Column Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3a2e6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fdb7530889b43df9437b70bdbbb8cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Column:', options=('Respondent_id (KANSOS ID)', 'Fieldwork country', 'PersistentR…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b0048cb4c642bea751829c564be85f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Select Values:', options=(), style=DescriptionStyle(description_width='initial'), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ce50eb6f8542038bf3af2cff2e16d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Add Filter', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8b07ca77b64d0ca9a4f2076cb2018b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Apply All Filters', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added filter: Brand in ['Coca-Cola/Coca-Cola Classic', 'Fanta', 'Sprite']\n",
      "Column 'Brand' found in DataFrame.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Respondent_id (KANSOS ID)</th>\n",
       "      <th>Fieldwork country</th>\n",
       "      <th>PersistentRespondentId</th>\n",
       "      <th>Timings_yyyymmdd</th>\n",
       "      <th>Timings_WeekNumber</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month and Year</th>\n",
       "      <th>Weighting variable</th>\n",
       "      <th>...</th>\n",
       "      <th>BEAST - CM_GrpdSegs</th>\n",
       "      <th>BEAST - MarketFactors_SoEUnrealised</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "      <th>None</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I_202212_BRA_434393844</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220326.0</td>\n",
       "      <td>202212.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>2.5113</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202212_BRA_4343938442022041</td>\n",
       "      <td>I_202212_BRA_434393844</td>\n",
       "      <td>434393844</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I_202212_BRA_464393944</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220327.0</td>\n",
       "      <td>202212.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202212_BRA_4643939442022041</td>\n",
       "      <td>I_202212_BRA_464393944</td>\n",
       "      <td>464393944</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I_202212_BRA_464393946</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220327.0</td>\n",
       "      <td>202212.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202212_BRA_4643939462022041</td>\n",
       "      <td>I_202212_BRA_464393946</td>\n",
       "      <td>464393946</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I_202213_BRA_404084541</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220401.0</td>\n",
       "      <td>202213.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>1.3867</td>\n",
       "      <td>...</td>\n",
       "      <td>Steady</td>\n",
       "      <td>0.435618</td>\n",
       "      <td>I_202213_BRA_4040845412022041</td>\n",
       "      <td>I_202213_BRA_404084541</td>\n",
       "      <td>404084541</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I_202213_BRA_404094948</td>\n",
       "      <td>Brazil</td>\n",
       "      <td></td>\n",
       "      <td>20220401.0</td>\n",
       "      <td>202213.0</td>\n",
       "      <td>Coca-Cola/Coca-Cola Classic</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>April 2022</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>...</td>\n",
       "      <td>Uncommitted</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>I_202213_BRA_4040949482022041</td>\n",
       "      <td>I_202213_BRA_404094948</td>\n",
       "      <td>404094948</td>\n",
       "      <td>202204.0</td>\n",
       "      <td>BRA</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TRUE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Respondent_id (KANSOS ID) Fieldwork country PersistentRespondentId  \\\n",
       "0    I_202212_BRA_434393844            Brazil                          \n",
       "1    I_202212_BRA_464393944            Brazil                          \n",
       "2    I_202212_BRA_464393946            Brazil                          \n",
       "3    I_202213_BRA_404084541            Brazil                          \n",
       "4    I_202213_BRA_404094948            Brazil                          \n",
       "\n",
       "   Timings_yyyymmdd  Timings_WeekNumber                        Brand  Month  \\\n",
       "0        20220326.0            202212.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "1        20220327.0            202212.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "2        20220327.0            202212.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "3        20220401.0            202213.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "4        20220401.0            202213.0  Coca-Cola/Coca-Cola Classic    4.0   \n",
       "\n",
       "     Year Month and Year  Weighting variable  ...  BEAST - CM_GrpdSegs  \\\n",
       "0  2022.0     April 2022              2.5113  ...               Steady   \n",
       "1  2022.0     April 2022              0.8579  ...               Steady   \n",
       "2  2022.0     April 2022              0.8579  ...               Steady   \n",
       "3  2022.0     April 2022              1.3867  ...               Steady   \n",
       "4  2022.0     April 2022              0.8464  ...          Uncommitted   \n",
       "\n",
       "   BEAST - MarketFactors_SoEUnrealised                           None  \\\n",
       "0                             0.000000  I_202212_BRA_4343938442022041   \n",
       "1                             0.000000  I_202212_BRA_4643939442022041   \n",
       "2                             0.000000  I_202212_BRA_4643939462022041   \n",
       "3                             0.435618  I_202213_BRA_4040845412022041   \n",
       "4                             0.000000  I_202213_BRA_4040949482022041   \n",
       "\n",
       "                     None       None      None  None  None  None  None  \n",
       "0  I_202212_BRA_434393844  434393844  202204.0   BRA   1.0   0.0  TRUE  \n",
       "1  I_202212_BRA_464393944  464393944  202204.0   BRA   1.0   1.0  TRUE  \n",
       "2  I_202212_BRA_464393946  464393946  202204.0   BRA   1.0   1.0  TRUE  \n",
       "3  I_202213_BRA_404084541  404084541  202204.0   BRA   1.0   0.0  TRUE  \n",
       "4  I_202213_BRA_404094948  404094948  202204.0   BRA   1.0   0.0  TRUE  \n",
       "\n",
       "[5 rows x 106 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming data_view_renamed is your DataFrame (load it dynamically)\n",
    "# Example DataFrame (replace this with your actual data loading code)\n",
    "# data_view_renamed = pd.read_spss(\"your_data_file.sav\")  # Replace with your actual file path\n",
    "\n",
    "# Create a dropdown widget for selecting the column (populate options dynamically)\n",
    "column_selector = widgets.Dropdown(\n",
    "    options=data_view_renamed.columns,\n",
    "    description='Select Column:',\n",
    "    style={'description_width': 'initial'},\n",
    ")\n",
    "\n",
    "# Create a SelectMultiple widget for selecting multiple values (initially empty, to be populated dynamically)\n",
    "value_selector = widgets.SelectMultiple(\n",
    "    options=[],\n",
    "    description='Select Values:',\n",
    "    style={'description_width': 'initial'},\n",
    ")\n",
    "\n",
    "# Button to add the filter\n",
    "add_filter_button = widgets.Button(description=\"Add Filter\")\n",
    "# Button to apply all filters\n",
    "apply_filters_button = widgets.Button(description=\"Apply All Filters\")\n",
    "\n",
    "# List to store the filters\n",
    "filters = []\n",
    "\n",
    "# Function to update value dropdown based on the selected column\n",
    "def update_value_dropdown(*args):\n",
    "    selected_column = column_selector.value\n",
    "    unique_values = data_view_renamed[selected_column].unique()\n",
    "    value_selector.options = unique_values\n",
    "\n",
    "# Update value dropdown whenever the selected column changes\n",
    "column_selector.observe(update_value_dropdown, 'value')\n",
    "\n",
    "# Function to add a filter to the list\n",
    "def add_filter(button):\n",
    "    selected_column = column_selector.value\n",
    "    selected_values = list(value_selector.value)\n",
    "    filters.append((selected_column, selected_values))\n",
    "    print(f\"Added filter: {selected_column} in {selected_values}\")\n",
    "\n",
    "# Function to apply all filters and display the filtered DataFrame\n",
    "def apply_filters(button):\n",
    "    global filtered_df\n",
    "    filtered_df = data_view_renamed.copy()\n",
    "    for column, values in filters:\n",
    "        filtered_df = filtered_df[filtered_df[column].isin(values)]\n",
    "        print(f\"Column '{column}' found in DataFrame.\")\n",
    "    display(filtered_df.head())\n",
    "\n",
    "# Bind the functions to the button click events\n",
    "add_filter_button.on_click(add_filter)\n",
    "apply_filters_button.on_click(apply_filters)\n",
    "\n",
    "# Display the UI components\n",
    "display(column_selector)\n",
    "display(value_selector)\n",
    "display(add_filter_button)\n",
    "display(apply_filters_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceb64cf",
   "metadata": {},
   "source": [
    "#### Converting the required imageries columns data to intergers (\"Yes\" to 1 \"No\" to 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94cd2e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5effae5161e04dcb825b5636b011cd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(SelectMultiple(description='Available Columns', options=('Respondent_id (KANSOS ID)', 'Fieldwor…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fbb6ab298f4d7abdbcd5dd041a9a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected columns: []\n",
      "No columns selected.\n",
      "Selected columns: ['BrandPowerGrid - Meaningful_Factor', 'BrandPowerGrid - Difference_Factor', 'BrandPowerGrid - Salience_Factor', 'BrandPowerGrid - Power', 'BrandPowerGrid - Potential', 'BrandPowerGrid - Meaningful_Power_Weight', 'BrandPowerGrid - Difference_Power_Weight', 'BrandPowerGrid - Salience_Power_Weight', 'BrandPowerGrid - Meaningful_Premium_Weight', 'BrandPowerGrid - Difference_Premium_Weight', 'BrandPowerGrid - Salience_Premium_Weight', 'BrandPowerGrid - Price_worth', 'BrandPowerGrid - CL_', 'BrandPowerGrid - Share_Gap', 'BrandPowerGrid - Cluster', 'BrandPowerGrid - M_contributionR2', 'BrandPowerGrid - D_contributionR2', 'BrandPowerGrid - S_contributionR2', 'BrandPowerGrid - Dependent', 'BrandPowerGrid - PowerIndex', 'BrandPowerGrid - ShareDependent', 'BrandPowerGrid - Loyalty', 'BrandPowerGrid - PriceDiagnostic', 'BrandPowerGrid - KWP_VolFlow', 'BEAST_MarketShare - Secure', 'BEAST_MarketShare - Unsupported', 'BEAST_MarketShare - Unrealised', 'BEAST_MarketShare - Secure_high', 'BEAST_MarketShare - Secure_low', 'BEAST_MarketShare - Unsupported_defect', 'BEAST_MarketShare - Unsupported_less', 'BEAST_MarketShare - Unrealised_new', 'BEAST_MarketShare - Unrealised_more', 'BEAST - CM_Segs', 'BEAST - CM_GrpdSegs', 'BEAST - MarketFactors_SoEUnrealised', None, None, None, None, None, None, None, None]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_872\\3548092042.py\u001b[0m in \u001b[0;36msubmit_columns\u001b[1;34m(b)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselected_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0mfiltered_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Yes'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'No'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Column '{column}' not found in DataFrame.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8846\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8847\u001b[0m         )\n\u001b[1;32m-> 8848\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"apply\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8850\u001b[0m     def applymap(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 733\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    734\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 857\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    858\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    859\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    871\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    874\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_872\\3548092042.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mselected_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                 \u001b[0mfiltered_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Yes'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'No'\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Column '{column}' not found in DataFrame.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1525\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1527\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1528\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# all_columns=data_view_renamed.copy()\n",
    "\n",
    "# Define the widgets\n",
    "available_columns_widget = widgets.SelectMultiple(\n",
    "    options=filtered_df.columns,\n",
    "    description='Available Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "selected_columns_widget = widgets.SelectMultiple(\n",
    "    options=[],\n",
    "    description='Selected Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button to add selected columns\n",
    "add_button = widgets.Button(description=\"Add ->\")\n",
    "\n",
    "# Button to remove selected columns\n",
    "remove_button = widgets.Button(description=\"<- Remove\")\n",
    "\n",
    "# Button to submit the selection\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "# Functions to handle button clicks\n",
    "def add_columns(b):\n",
    "    selected = available_columns_widget.value\n",
    "    new_selected_columns = [col for col in selected if col not in selected_columns_widget.options]\n",
    "    if new_selected_columns:\n",
    "        # Remove selected columns from the available columns\n",
    "        available_columns_widget.options = [col for col in available_columns_widget.options if col not in selected]\n",
    "        # Add to selected columns\n",
    "        selected_columns_widget.options = list(selected_columns_widget.options) + new_selected_columns\n",
    "\n",
    "def remove_columns(b):\n",
    "    selected = selected_columns_widget.value\n",
    "    if selected:\n",
    "        # Add removed columns back to the available columns\n",
    "        available_columns_widget.options = list(available_columns_widget.options) + list(selected)\n",
    "        # Remove from selected columns\n",
    "        selected_columns_widget.options = [col for col in selected_columns_widget.options if col not in selected]\n",
    "\n",
    "# Function to apply all filters and display the filtered DataFrame\n",
    "def submit_columns(b):\n",
    "    global filtered_df\n",
    "    selected_columns = list(selected_columns_widget.options)\n",
    "     # Print selected columns to verify\n",
    "    print(\"Selected columns:\", selected_columns)\n",
    "    \n",
    "    if not selected_columns:\n",
    "        print(\"No columns selected.\")\n",
    "    else:\n",
    "        # Apply the conversion only to selected columns\n",
    "        for column in selected_columns:\n",
    "            if column in filtered_df.columns:\n",
    "                filtered_df[column] = filtered_df[column].apply(lambda x: 1 if x == 'Yes' else (0 if x == 'No' else x))\n",
    "            else:\n",
    "                print(f\"Column '{column}' not found in DataFrame.\")\n",
    "    \n",
    "        # Display the updated DataFrame\n",
    "        display(filtered_df.head())\n",
    "        print(\"Selected columns converted\")\n",
    "\n",
    "# Assign button actions\n",
    "add_button.on_click(add_columns)\n",
    "remove_button.on_click(remove_columns)\n",
    "submit_button.on_click(submit_columns)\n",
    "\n",
    "# Display the UI\n",
    "display(widgets.HBox([available_columns_widget, widgets.VBox([add_button, remove_button]), selected_columns_widget]))\n",
    "display(submit_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6326eda2",
   "metadata": {},
   "source": [
    "#### Calculate Weighted Mean and Frequency - Weights On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7422b5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "# Function to clear the sheet and its formatting by deleting and recreating it\n",
    "def clear_excel_sheet(output_path, sheet_name):\n",
    "    if os.path.exists(output_path):\n",
    "        book = load_workbook(output_path)\n",
    "        # Remove all sheets\n",
    "        for sheet in book.sheetnames:\n",
    "            std = book[sheet]\n",
    "            book.remove(std)\n",
    "        # Create the Results sheet\n",
    "        book.create_sheet(sheet_name)\n",
    "        book.save(output_path)\n",
    "    else:\n",
    "        # Create a new workbook and add the Results sheet\n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "            writer.book.create_sheet(sheet_name)\n",
    "            \n",
    "            \n",
    "# Define function to calculate weighted mean and save to Excel\n",
    "def calculate_weighted_mean(weight_column, value_columns, output_path):\n",
    "    if weight_column and value_columns:\n",
    "        results = []\n",
    "        for value_column in value_columns:\n",
    "            mean = np.sum(filtered_df[value_column] * filtered_df[weight_column]) / np.sum(filtered_df[weight_column])\n",
    "            print(f\"Weighted Mean of {value_column}: {mean}\")\n",
    "            results.append({'Measure': value_column, 'Weighted Mean': mean})\n",
    "\n",
    "        result_df = pd.DataFrame(results)\n",
    "        \n",
    "        clear_excel_sheet(output_path, 'Results')\n",
    "\n",
    "        # Load existing workbook if it exists, otherwise create a new one\n",
    "        if os.path.exists(output_path):\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "                result_df.to_excel(writer, sheet_name='Results', index=False, startrow=2, header=['Measure', 'Weighted Mean'])\n",
    "        else:\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                result_df.to_excel(writer, sheet_name='Results', index=False, startrow=2, header=['Measure', 'Weighted Mean'])\n",
    "        \n",
    "        print(f\"Results have been saved to '{output_path}' in the 'Results' sheet.\")\n",
    "    else:\n",
    "        print(\"Please select both weight and value columns.\")\n",
    "\n",
    "# Define function to calculate weighted frequency and save to Excel\n",
    "def calculate_weighted_frequency(weight_column, category_columns, output_path):\n",
    "    if weight_column and category_columns:\n",
    "        # Load existing workbook and determine the start row\n",
    "        if os.path.exists(output_path):\n",
    "            book = load_workbook(output_path)\n",
    "            sheet = book['Results']\n",
    "            startrow = sheet.max_row + 2\n",
    "        else:\n",
    "            startrow = 5\n",
    "\n",
    "        # Write each category's weighted frequency\n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl', mode='a', if_sheet_exists='overlay') as writer:\n",
    "            for category_column in category_columns:\n",
    "                weighted_counts = filtered_df.groupby(category_column).apply(lambda x: np.sum(x[weight_column])).reset_index(name='Weighted Count')\n",
    "                print(f\"Weighted Frequencies for {category_column}:\")\n",
    "                print(weighted_counts)\n",
    "\n",
    "                weighted_counts.to_excel(writer, sheet_name='Results', index=False, startrow=startrow, header=[category_column, 'Weighted Frequency'])\n",
    "                startrow += len(weighted_counts) + 2  # Adjust startrow for the next calculation\n",
    "        \n",
    "        print(f\"Results have been saved to '{output_path}' in the 'Results' sheet.\")\n",
    "    else:\n",
    "        print(\"Please select both weight and category columns.\")\n",
    "        \n",
    "# Create dropdown widgets for selecting columns\n",
    "weight_column_Dropdown = widgets.Dropdown(\n",
    "    options=[(col, col) for col in filtered_df.columns],\n",
    "    description='Weight Column:',\n",
    ")\n",
    "\n",
    "value_column_SelectMultiple = widgets.SelectMultiple(\n",
    "    options=[(col, col) for col in filtered_df.columns if col != weight_column_Dropdown.value],\n",
    "    description='Value Column:',\n",
    ")\n",
    "\n",
    "category_column_SelectMultiple = widgets.SelectMultiple(\n",
    "    options=[(col, col) for col in filtered_df.columns if col != weight_column_Dropdown.value],\n",
    "    description='Category Column:',\n",
    ")\n",
    "\n",
    "# Create buttons to calculate weighted mean and frequency\n",
    "calculate_mean_button = widgets.Button(description=\"Calculate Weighted Mean\")\n",
    "calculate_frequency_button = widgets.Button(description=\"Calculate Weighted Frequency\")\n",
    "\n",
    "# Define button click handlers\n",
    "def on_calculate_mean_button_clicked(b):\n",
    "    calculate_weighted_mean(weight_column_Dropdown.value, value_column_SelectMultiple.value, output_path)\n",
    "\n",
    "def on_calculate_frequency_button_clicked(b):\n",
    "    calculate_weighted_frequency(weight_column_Dropdown.value, category_column_SelectMultiple.value, output_path)\n",
    "\n",
    "# Link buttons to handlers\n",
    "calculate_mean_button.on_click(on_calculate_mean_button_clicked)\n",
    "calculate_frequency_button.on_click(on_calculate_frequency_button_clicked)\n",
    "\n",
    "# Display widgets\n",
    "display(weight_column_Dropdown)\n",
    "display(value_column_SelectMultiple)\n",
    "display(calculate_mean_button)\n",
    "display(category_column_SelectMultiple)\n",
    "display(calculate_frequency_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36525c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Awareness'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ebbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Remove null value\n",
    "filtered_df_clean = filtered_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20597f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52aadf",
   "metadata": {},
   "source": [
    "## Split file by Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189cfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming `filtered_df_clean` is your DataFrame\n",
    "# Create a multi-select dropdown for selecting the columns to sort by\n",
    "sort_multi_select = widgets.SelectMultiple(\n",
    "    options=filtered_df_clean.columns,  # Get the columns from the DataFrame\n",
    "    description='Sort by:',\n",
    "    rows=6\n",
    ")\n",
    "\n",
    "# Create a checkbox to select ascending or descending sorting\n",
    "sort_order_checkbox = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Sort Ascending'\n",
    ")\n",
    "\n",
    "# Create a button to trigger the sorting\n",
    "sort_button = widgets.Button(\n",
    "    description=\"Sort DataFrame\",\n",
    "    button_style=\"primary\",  # Color the button\n",
    "    icon='check'  # Add a check icon to the button\n",
    ")\n",
    "\n",
    "# Variable to store the sorted DataFrame\n",
    "sorted_df = None\n",
    "\n",
    "# Function to sort the DataFrame based on the selected columns\n",
    "def sort_dataframe(b):\n",
    "    global sorted_df\n",
    "    columns = sort_multi_select.value  # Get selected columns\n",
    "    ascending = sort_order_checkbox.value  # Get sort order\n",
    "    \n",
    "    if columns:  # If columns are selected\n",
    "        sorted_df = filtered_df_clean.sort_values(by=list(columns), ascending=ascending)\n",
    "        display(sorted_df)  # Display the sorted DataFrame\n",
    "        print(\"DataFrame sorted and saved.\")\n",
    "    else:\n",
    "        print(\"Please select at least one column to sort by.\")\n",
    "\n",
    "# Link the button to the sorting function\n",
    "sort_button.on_click(sort_dataframe)\n",
    "\n",
    "# Create a UI layout\n",
    "ui = widgets.VBox([\n",
    "    widgets.Label(\"Sort the DataFrame by multiple columns:\"),\n",
    "    sort_multi_select,\n",
    "    sort_order_checkbox,\n",
    "    sort_button\n",
    "])\n",
    "\n",
    "# Display the UI\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5a93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d319150a",
   "metadata": {},
   "source": [
    "##### Step3: Prepare endorsements for all the variables of  selection - Please select weights to prepare weighted endorsements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33198389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create widgets for column selection\n",
    "all_columns = sorted_df.columns.tolist()\n",
    "selected_columns = []\n",
    "\n",
    "# Define the widgets\n",
    "available_columns_widget = widgets.SelectMultiple(\n",
    "    options=all_columns,\n",
    "    description='Available Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "selected_columns_widget = widgets.SelectMultiple(\n",
    "    options=selected_columns,\n",
    "    description='Selected Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Dropdown for selecting weight column (optional)\n",
    "weight_column_dropdown = widgets.Dropdown(\n",
    "    options=[None] + all_columns,  # Allow \"None\" as an option\n",
    "    description='Weight Column:',\n",
    "    value=None  # Default to None\n",
    ")\n",
    "\n",
    "# Button to add selected columns\n",
    "add_button = widgets.Button(description=\"Add ->\")\n",
    "\n",
    "# Button to remove selected columns\n",
    "remove_button = widgets.Button(description=\"<- Remove\")\n",
    "\n",
    "# Button to submit the selection\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "# Functions to handle button clicks\n",
    "def add_columns(b):\n",
    "    selected = available_columns_widget.value\n",
    "    new_selected_columns = [col for col in selected if col not in selected_columns_widget.options]\n",
    "    if new_selected_columns:\n",
    "        # Remove selected columns from the available columns\n",
    "        available_columns_widget.options = [col for col in available_columns_widget.options if col not in selected]\n",
    "        # Add to selected columns\n",
    "        selected_columns_widget.options = list(selected_columns_widget.options) + new_selected_columns\n",
    "\n",
    "def remove_columns(b):\n",
    "    selected = selected_columns_widget.value\n",
    "    if selected:\n",
    "        # Add removed columns back to the available columns\n",
    "        available_columns_widget.options = list(available_columns_widget.options) + list(selected)\n",
    "        # Remove from selected columns\n",
    "        selected_columns_widget.options = [col for col in selected_columns_widget.options if col not in selected]\n",
    "def submit_columns(b):\n",
    "    if selected_columns_widget.options:\n",
    "        selected_cols = list(selected_columns_widget.options)\n",
    "        weight_col = weight_column_dropdown.value\n",
    "        \n",
    "        # Filter the DataFrame to only include numeric columns\n",
    "        numeric_cols = sorted_df[selected_cols].select_dtypes(include='number')\n",
    "        if weight_col:\n",
    "            # Ensure that the weight column is also numeric\n",
    "            if pd.api.types.is_numeric_dtype(sorted_df[weight_col]):\n",
    "                mean_values_by_brand = sorted_df.groupby('Brand').apply(\n",
    "                    lambda x: (numeric_cols.loc[x.index].multiply(x[weight_col], axis=0).sum() / x[weight_col].sum())\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Weight column '{weight_col}' is not numeric. Please select a valid numeric column.\")\n",
    "                return\n",
    "        else:\n",
    "            mean_values_by_brand = sorted_df.groupby('Brand')[numeric_cols.columns].mean(numeric_only=True)\n",
    "\n",
    "        # Convert mean values to percentages without rounding\n",
    "        mean_values_by_brand_percentage = (mean_values_by_brand * 100)\n",
    "\n",
    "        # Reformat the DataFrame to place the \"Brand\" values above the means\n",
    "        mean_values_transposed = mean_values_by_brand_percentage.T\n",
    "        mean_values_transposed.columns.name = None  # Remove the name from the columns\n",
    "        \n",
    "        # Rename the index (left-side variable) to \"ENDORSEMENTS\"\n",
    "        mean_values_transposed.index.name = \"ENDORSEMENTS\"\n",
    "        \n",
    "        # Calculate the base (count of each brand)\n",
    "        base_counts = sorted_df.groupby('Brand').size()\n",
    "        \n",
    "        # Create a new DataFrame with the \"BASE\" row\n",
    "        base_row = pd.DataFrame(base_counts).T\n",
    "        base_row.index = ['BASE']\n",
    "        \n",
    "        # Combine the \"BASE\" row with the transposed mean values DataFrame\n",
    "        result_df = pd.concat([base_row, mean_values_transposed])\n",
    "        \n",
    "        # Format the mean values as percentages without rounding\n",
    "        result_df.iloc[1:] = result_df.iloc[1:].applymap(lambda x: f'{x:.2f}%' if isinstance(x, float) else x)\n",
    "        \n",
    "        # Display the DataFrame\n",
    "        display(result_df)\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            # Load existing sheets\n",
    "            existing_sheets = pd.ExcelFile(output_path).sheet_names\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl', mode='a', if_sheet_exists='new') as writer:\n",
    "                # Write the new DataFrame to a new sheet\n",
    "                result_df.to_excel(writer, sheet_name='Endorsement', index=True, startrow=8)\n",
    "        else:\n",
    "            # Create a new file and write the DataFrame\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                result_df.to_excel(writer, sheet_name='Endorsement', index=True, startrow=8)\n",
    "        \n",
    "        print(f\"Results have been saved to '{output_path}' in the 'Endorsement' sheet, starting from row 9.\")\n",
    "    else:\n",
    "        print(\"No columns selected. Please select at least one column.\")\n",
    "\n",
    "\n",
    "# Assign button actions\n",
    "add_button.on_click(add_columns)\n",
    "remove_button.on_click(remove_columns)\n",
    "submit_button.on_click(submit_columns)\n",
    "\n",
    "# Display the UI\n",
    "display(widgets.HBox([available_columns_widget, widgets.VBox([add_button, remove_button]), selected_columns_widget]))\n",
    "display(weight_column_dropdown)  # Add weight column dropdown\n",
    "display(submit_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18967a89",
   "metadata": {},
   "source": [
    "##### Step4 correaltion for any brands you selct from filter and get that in tab of excel sheet. (all this for aware =1) - Please select weights to calculate correlation based on weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d4232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Create widgets for brand and column selection\n",
    "brands = sorted_df['Brand'].unique().tolist()\n",
    "all_columns = sorted_df.columns.tolist()\n",
    "selected_columns = []\n",
    "\n",
    "# Dropdown for selecting weight column (optional)\n",
    "weight_column_dropdown = widgets.Dropdown(\n",
    "    options=[None] + all_columns,  # Allow \"None\" as an option\n",
    "    description='Weight Column:',\n",
    "    value=None  # Default to None\n",
    ")\n",
    "\n",
    "brand_widget = widgets.SelectMultiple(\n",
    "    options=brands,\n",
    "    description='Brands',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "available_columns_widget = widgets.SelectMultiple(\n",
    "    options=all_columns,\n",
    "    description='Available Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "selected_columns_widget = widgets.SelectMultiple(\n",
    "    options=selected_columns,\n",
    "    description='Selected Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button to add selected columns\n",
    "add_button = widgets.Button(description=\"Add ->\")\n",
    "\n",
    "# Button to remove selected columns\n",
    "remove_button = widgets.Button(description=\"<- Remove\")\n",
    "\n",
    "# Button to submit the selection\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "# Functions to handle button clicks\n",
    "def add_columns(b):\n",
    "    selected = available_columns_widget.value\n",
    "    new_selected_columns = [col for col in selected if col not in selected_columns_widget.options]\n",
    "    if new_selected_columns:\n",
    "        available_columns_widget.options = [col for col in available_columns_widget.options if col not in selected]\n",
    "        selected_columns_widget.options = list(selected_columns_widget.options) + new_selected_columns\n",
    "\n",
    "def remove_columns(b):\n",
    "    selected = selected_columns_widget.value\n",
    "    if selected:\n",
    "        available_columns_widget.options = list(available_columns_widget.options) + list(selected)\n",
    "        selected_columns_widget.options = [col for col in selected_columns_widget.options if col not in selected]\n",
    "\n",
    "def submit_columns(b):\n",
    "    if selected_columns_widget.options and brand_widget.value:\n",
    "        selected_cols = list(selected_columns_widget.options)\n",
    "        selected_brands = list(brand_widget.value)\n",
    "        weight_col = weight_column_dropdown.value  # Get the selected weight column\n",
    "        \n",
    "        # Filter the DataFrame for the selected brands\n",
    "        filtered_df_2 = sorted_df[sorted_df['Brand'].isin(selected_brands)]\n",
    "        \n",
    "        # Ensure the selected columns contain only numeric data\n",
    "        numeric_cols = filtered_df_2[selected_cols].select_dtypes(include='number')\n",
    "        \n",
    "        if weight_col:\n",
    "            # Ensure the weight column is numeric\n",
    "            if pd.api.types.is_numeric_dtype(filtered_df_2[weight_col]):\n",
    "                # Apply weights to calculate weighted correlation\n",
    "                weighted_df = numeric_cols.multiply(filtered_df_2[weight_col], axis=0)\n",
    "                corr_matrix = weighted_df.corr()\n",
    "                # Add '_weight' suffix to the sheet name if a weight column is selected\n",
    "                suffix = \"_weight\"\n",
    "            else:\n",
    "                print(f\"Weight column '{weight_col}' is not numeric. Please select a valid numeric column.\")\n",
    "                return\n",
    "        else:\n",
    "            # Simple correlation without weights\n",
    "            corr_matrix = numeric_cols.corr()\n",
    "            suffix = \"\"  # No suffix if no weight column is selected\n",
    "        \n",
    "        # Format the correlation matrix to 2 decimal places\n",
    "        corr_matrix = corr_matrix.round(3)\n",
    "        \n",
    "        # Prepare the sheet name using the selected brand names\n",
    "        brand_names_str = \"_\".join(map(str, selected_brands))\n",
    "        sheet_name = f'Correlation_{brand_names_str}{suffix}'\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            # Load the existing workbook\n",
    "            book = load_workbook(output_path)\n",
    "            # Check if the sheet already exists\n",
    "            if sheet_name in book.sheetnames:\n",
    "                # If the sheet exists, delete it first and save the workbook\n",
    "                del book[sheet_name]\n",
    "                book.save(output_path)  # Save after deletion to update the workbook\n",
    "                print(f\"Sheet '{sheet_name}' already exists. Replacing with the new data.\")\n",
    "            else:\n",
    "                print(f\"Creating new sheet '{sheet_name}'.\")\n",
    "            \n",
    "            # Reopen the workbook to append the new sheet with updated data\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl', mode='a') as writer:\n",
    "                writer.book = load_workbook(output_path)  # Reopen the workbook\n",
    "                corr_matrix.to_excel(writer, sheet_name=sheet_name, index=True, startrow=8)\n",
    "        else:\n",
    "            # Create a new workbook and write to it\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "                corr_matrix.to_excel(writer, sheet_name=sheet_name, index=True, startrow=8)\n",
    "        \n",
    "        # Load the workbook to apply conditional formatting\n",
    "        book = load_workbook(output_path)\n",
    "        sheet = book[sheet_name]\n",
    "        \n",
    "        # Define the styles\n",
    "        sky_blue_fill = PatternFill(start_color=\"87CEEB\", end_color=\"87CEEB\", fill_type=\"solid\")\n",
    "        black_fill = PatternFill(start_color=\"000000\", end_color=\"000000\", fill_type=\"solid\")\n",
    "        white_font = Font(color=\"FFFFFF\")\n",
    "\n",
    "        # Apply the formatting\n",
    "        for row in sheet.iter_rows(min_row=9, min_col=2, max_col=sheet.max_column, max_row=sheet.max_row):\n",
    "            for cell in row:\n",
    "                if isinstance(cell.value, (int, float)):\n",
    "                    if cell.value > 0.5 and cell.value < 1:\n",
    "                        cell.fill = sky_blue_fill\n",
    "                    elif cell.value == 1:\n",
    "                        cell.fill = black_fill\n",
    "                        cell.font = white_font\n",
    "\n",
    "        # Save the workbook with the formatting\n",
    "        book.save(output_path)\n",
    "        print(\"Correlation matrix calculations are done and saved!\")\n",
    "    else:\n",
    "        print(\"Please select at least one brand and one column.\")\n",
    "\n",
    "# Assign button actions\n",
    "add_button.on_click(add_columns)\n",
    "remove_button.on_click(remove_columns)\n",
    "submit_button.on_click(submit_columns)\n",
    "\n",
    "# Display the UI\n",
    "display(widgets.HBox([brand_widget, available_columns_widget, widgets.VBox([add_button, remove_button]), selected_columns_widget]))\n",
    "display(weight_column_dropdown)  # Add weight column dropdown\n",
    "display(submit_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af048717",
   "metadata": {},
   "source": [
    "#### >>>>>>>>>>>>>>FACTOR ANALYSIS<<<<<<<<<<<<<<<<<<<\n",
    "<!-- Weights off - Yet to implement weight case -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d449894b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install factor-analyzer --trusted-host pypi.org --trusted-host files.pythonhosted.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.head()\n",
    "# # filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b57cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets, HBox, VBox, Label\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Assuming filtered_df is your DataFrame\n",
    "all_columns = sorted_df.columns.tolist()\n",
    "selected_columns = []\n",
    "\n",
    "# Extract unique brands\n",
    "brands = sorted_df['Brand'].unique().tolist()\n",
    "\n",
    "# Define the widgets\n",
    "available_columns_widget = widgets.SelectMultiple(\n",
    "    options=all_columns,\n",
    "    description='Available Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "selected_columns_widget = widgets.SelectMultiple(\n",
    "    options=selected_columns,\n",
    "    description='Selected Columns',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "num_factors_widget = widgets.IntText(\n",
    "    description='Number of Factors:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Multi-selector for brands\n",
    "brands_widget = widgets.SelectMultiple(\n",
    "    options=brands,\n",
    "    description='Select Brands',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button to add selected columns\n",
    "add_button = widgets.Button(description=\"Add ->\")\n",
    "\n",
    "# Button to remove selected columns\n",
    "remove_button = widgets.Button(description=\"<- Remove\")\n",
    "\n",
    "# Button to submit the selection\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "\n",
    "# Functions to handle button clicks\n",
    "def add_columns(b):\n",
    "    selected = available_columns_widget.value\n",
    "    new_selected_columns = [col for col in selected if col not in selected_columns_widget.options]\n",
    "    if new_selected_columns:\n",
    "        available_columns_widget.options = [col for col in available_columns_widget.options if col not in selected]\n",
    "        selected_columns_widget.options = list(selected_columns_widget.options) + new_selected_columns\n",
    "\n",
    "def remove_columns(b):\n",
    "    selected = selected_columns_widget.value\n",
    "    if selected:\n",
    "        available_columns_widget.options = list(available_columns_widget.options) + list(selected)\n",
    "        selected_columns_widget.options = [col for col in selected_columns_widget.options if col not in selected]\n",
    "\n",
    "def submit_columns(b):\n",
    "    global analysis_df \n",
    "    if selected_columns_widget.options and num_factors_widget.value:\n",
    "        selected_cols = list(selected_columns_widget.options)\n",
    "        selected_brands = list(brands_widget.value)\n",
    "        print(f\"Selected brands is : {selected_brands}\")\n",
    "        \n",
    "        # Filter DataFrame based on selected brands\n",
    "        filtered_df_brands = sorted_df[sorted_df['Brand'].isin(selected_brands)]\n",
    "        analysis_df = filtered_df_brands[selected_cols]\n",
    "        print(analysis_df.shape)\n",
    "        \n",
    "        try:\n",
    "            # Perform factor analysis\n",
    "            num_factors = num_factors_widget.value\n",
    "            if num_factors > len(selected_cols):\n",
    "                raise ValueError(f\"Number of factors ({num_factors}) cannot exceed the number of selected columns ({len(selected_cols)}).\")\n",
    "            print(f\"Selected Columns: {selected_cols}\")\n",
    "            print(f\"Filtered DataFrame Shape: {analysis_df.shape}\")\n",
    "            print(f\"Number of Factors: {num_factors}\")\n",
    "            \n",
    "            # Perform factor analysis\n",
    "            cov_analysis_df = analysis_df.cov() \n",
    "            fa = FactorAnalyzer(n_factors=num_factors, method='principal',rotation=\"varimax\")\n",
    "            fa.fit(cov_analysis_df) # fit analysis_df only for correlation factor analysis\n",
    "            \n",
    "            ev, v = fa.get_eigenvalues()\n",
    "            print(ev)\n",
    "            plt.scatter(range(1,analysis_df.shape[1]+1),ev)\n",
    "            plt.plot(range(1,analysis_df.shape[1]+1),ev)\n",
    "            plt.title('Scree Plot')\n",
    "            plt.xlabel('Factors')\n",
    "            plt.ylabel('Eigenvalue')\n",
    "            plt.grid()\n",
    "            plt.show()\n",
    "            \n",
    "            # Get the factor loadings\n",
    "            loadings = fa.loadings_\n",
    "            loadings_df = pd.DataFrame(loadings, index=selected_cols, columns=[f'Factor {i+1}' for i in range(num_factors)])\n",
    "            print(loadings_df)\n",
    "\n",
    "            sheet_name = 'Factor Analysis'\n",
    "            \n",
    "            if os.path.exists(output_path):\n",
    "                # Load the workbook using openpyxl\n",
    "                book = load_workbook(output_path)\n",
    "                with pd.ExcelWriter(output_path, engine='openpyxl', mode='a') as writer:\n",
    "                    writer.book = book\n",
    "                    # Remove the existing sheet if it exists\n",
    "                    if sheet_name in book.sheetnames:\n",
    "                        del book[sheet_name]\n",
    "                    # Write loadings to Excel\n",
    "                    loadings_df.to_excel(writer, sheet_name=sheet_name)\n",
    "            else:\n",
    "                # Create a new workbook and save the results\n",
    "                with pd.ExcelWriter(output_path, engine='openpyxl', mode='w') as writer:\n",
    "                    loadings_df.to_excel(writer, sheet_name=sheet_name)\n",
    "\n",
    "            print(f\"Factor loadings saved to '{output_file}' in the '{sheet_name}' sheet.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error during factor analysis: {e}\")\n",
    "    else:\n",
    "        print(\"Please select at least one column, specify the number of factors, and select at least one brand.\")\n",
    "\n",
    "# Assign button actions\n",
    "add_button.on_click(add_columns)\n",
    "remove_button.on_click(remove_columns)\n",
    "submit_button.on_click(submit_columns)\n",
    "\n",
    "# Display the UI\n",
    "display(HBox([available_columns_widget, VBox([add_button, remove_button]), selected_columns_widget]))\n",
    "display(num_factors_widget)  # Display the IntText widget for number of factors\n",
    "display(brands_widget)  # Display the multi-selector for brands\n",
    "display(submit_button)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afd2f4d",
   "metadata": {},
   "source": [
    "# >>>>>>>>>>>>>>>>>>>>> Regression<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7b2066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>>>>> Enter and stepwise regression<<<<<<<<<\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Font\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Your code here\n",
    "\n",
    "\n",
    "# Assuming `filtered_df` is your input DataFrame\n",
    "columns = filtered_df.columns.tolist()\n",
    "\n",
    "# Extract unique brands from the 'Brand' column\n",
    "brands = filtered_df['Brand'].unique().tolist()\n",
    "\n",
    "# Create multi-select widgets for independent and dependent variables\n",
    "dependent_selector = widgets.Dropdown(\n",
    "    options=columns,\n",
    "    description='Dependent',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "independent_selector = widgets.SelectMultiple(\n",
    "    options=columns,\n",
    "    description='Independent',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Create a dropdown to select regression method\n",
    "method_selector = widgets.Dropdown(\n",
    "    options=['Enter', 'Stepwise'],\n",
    "    description='Method',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# for multi-brand selection, use SelectMultiple\n",
    "multi_brand_selector = widgets.SelectMultiple(\n",
    "    options=brands,\n",
    "    description='Select Brands',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Button to trigger the regression\n",
    "button = widgets.Button(description=\"Run Regression\")\n",
    "output = widgets.Output()\n",
    "\n",
    "# Display the selectors and the button\n",
    "display(multi_brand_selector,dependent_selector, independent_selector, method_selector, button, output)\n",
    "\n",
    "def filter_by_brand(df, selected_brands):\n",
    "    # Filter the DataFrame for the selected brand(s)\n",
    "    return df[df['Brand'].isin(selected_brands)]\n",
    "\n",
    "# Function to calculate VIF\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Variable\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [sm.OLS(X[col], sm.add_constant(X.drop(col, axis=1))).fit().rsquared for col in X.columns]\n",
    "    vif_data[\"VIF\"] = 1 / (1 - vif_data[\"VIF\"])\n",
    "    return vif_data\n",
    "\n",
    "# Function to perform stepwise regression\n",
    "# Updated stepwise_regression function with saving functionality\n",
    "def stepwise_regression(X, y, initial_list=[], threshold_in=0.05, threshold_out=0.10):\n",
    "    included = list(initial_list)\n",
    "    stepwise_results = []\n",
    "    step = 1\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    # Ensure output_path is provided for saving results\n",
    "    if output_path is None:\n",
    "        raise ValueError(\"Output path must be specified for saving results.\")\n",
    "    \n",
    "    while True:\n",
    "        excluded = list(set(X.columns) - set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        \n",
    "        for new_column in excluded:\n",
    "            X_temp = X[included + [new_column]]\n",
    "            scaler = StandardScaler()\n",
    "            X_temp_scaled = scaler.fit_transform(X_temp)\n",
    "            X_temp_scaled_df = pd.DataFrame(X_temp_scaled, columns=included + [new_column])\n",
    "            model = sm.OLS(y, sm.add_constant(X_temp_scaled_df)).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        \n",
    "        best_pval = new_pval.min()\n",
    "        \n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.idxmin()\n",
    "            included.append(best_feature)\n",
    "            X_included = X[included]\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_included)\n",
    "            X_scaled_df = pd.DataFrame(X_scaled, columns=included)\n",
    "            model = sm.OLS(y, sm.add_constant(X_scaled_df)).fit()\n",
    "\n",
    "            coefficients = model.params[1:]\n",
    "            standard_errors = model.bse[1:]\n",
    "            t_stats = model.tvalues[1:]\n",
    "            p_values = model.pvalues[1:]\n",
    "            standardized_coefficients = coefficients * (X_scaled_df.std() / y.std())\n",
    "            vif_df = calculate_vif(X_scaled_df)\n",
    "            \n",
    "            output_df = pd.DataFrame({\n",
    "                \n",
    "                'Standardized Coefficients (Beta)': standardized_coefficients,\n",
    "                'Sig. (p-value)': p_values\n",
    "                \n",
    "            })\n",
    "            \n",
    "            stepwise_results.append((f'Step {step} - Add {best_feature}', output_df))\n",
    "            step += 1\n",
    "            \n",
    "        \n",
    "        X_included = X[included]\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_included)\n",
    "        X_scaled_df = pd.DataFrame(X_scaled, columns=included)\n",
    "        model = sm.OLS(y, sm.add_constant(X_scaled_df)).fit()\n",
    "        pvalues = model.pvalues[1:]\n",
    "\n",
    "        worst_pval = pvalues.max()\n",
    "        \n",
    "        if worst_pval > threshold_out:\n",
    "            worst_feature = pvalues.idxmax()\n",
    "            included.remove(worst_feature)\n",
    "            X_included = X[included]\n",
    "            scaler = StandardScaler()\n",
    "            X_scaled = scaler.fit_transform(X_included)\n",
    "            X_scaled_df = pd.DataFrame(X_scaled, columns=included)\n",
    "            model = sm.OLS(y, sm.add_constant(X_scaled_df)).fit()\n",
    "\n",
    "            coefficients = model.params[1:]\n",
    "            standard_errors = model.bse[1:]\n",
    "            t_stats = model.tvalues[1:]\n",
    "            p_values = model.pvalues[1:]\n",
    "            standardized_coefficients = coefficients * (X_scaled_df.std() / y.std())\n",
    "            vif_df = calculate_vif(X_scaled_df)\n",
    "            \n",
    "            output_df = pd.DataFrame({\n",
    "                \n",
    "                'Standardized Coefficients (Beta)': standardized_coefficients,\n",
    "                'Sig. (p-value)': p_values\n",
    "            })\n",
    "            \n",
    "            stepwise_results.append((f'Step {step} - Remove {worst_feature}', output_df))\n",
    "            step += 1\n",
    "        \n",
    "        if best_pval >= threshold_in and worst_pval <= threshold_out:\n",
    "            break\n",
    "    \n",
    "    return stepwise_results, included\n",
    "\n",
    "def get_unique_sheet_name(base_name, workbook):\n",
    "    sheet_name= base_name\n",
    "    counter=1\n",
    "    while sheet_name in workbook.sheetnames:\n",
    "        sheet_name=f\"{base_name}{counter}\"\n",
    "        counter+=1\n",
    "    return sheet_name\n",
    "\n",
    "\n",
    "# Function to perform linear regression based on selections\n",
    "def run_regression(button):\n",
    "    global filtered_by_brand_df\n",
    "    with output:\n",
    "        clear_output()  # Clear previous output\n",
    "        \n",
    "        # Filter the DataFrame by selected brand(s)\n",
    "        selected_brands = list(multi_brand_selector.value) \n",
    "        if not selected_brands:\n",
    "            print(\"Please select at least one brand!\")\n",
    "            return\n",
    "        \n",
    "        filtered_by_brand_df = filter_by_brand(filtered_df, selected_brands)\n",
    "        \n",
    "        dependent_var = dependent_selector.value\n",
    "        independent_vars = list(independent_selector.value)\n",
    "        method = method_selector.value\n",
    "        \n",
    "        if not independent_vars or not dependent_var:\n",
    "            print(\"Please select both dependent and independent variables!\")\n",
    "            return\n",
    "\n",
    "        X = filtered_by_brand_df[independent_vars]\n",
    "        y = filtered_by_brand_df[dependent_var]\n",
    "\n",
    "        X_with_const = sm.add_constant(X)\n",
    "\n",
    "        if method == 'Enter':\n",
    "            # Perform Enter regression\n",
    "            model = sm.OLS(y, X_with_const).fit()\n",
    "\n",
    "            # Extract coefficients and metrics\n",
    "            coefficients = model.params\n",
    "            standard_errors = model.bse\n",
    "            t_stats = model.tvalues\n",
    "            p_values = model.pvalues\n",
    "            standardized_coefficients = coefficients * (X_with_const.std() / y.std())\n",
    "\n",
    "            # Create DataFrame for the Enter results\n",
    "            enter_result_df = pd.DataFrame({\n",
    "                'Unstandardized Coefficients (B)': coefficients,\n",
    "                'Standardized Coefficients (Beta)': standardized_coefficients,\n",
    "                'Standard Error': standard_errors,\n",
    "                't': t_stats,\n",
    "                'Sig. (p-value)': p_values\n",
    "            })\n",
    "\n",
    "            # Write Enter regression results to Excel\n",
    "            with pd.ExcelWriter(output_path, engine='openpyxl', mode='a' if os.path.exists(output_path) else 'w') as writer:\n",
    "                workbook = writer.book\n",
    "                sheet_name = get_unique_sheet_name('Enter Results', workbook)  # Get unique sheet name\n",
    "                enter_result_df.to_excel(writer, sheet_name=sheet_name, index=True)\n",
    "\n",
    "            print(\"Enter regression completed and saved.\")\n",
    "\n",
    "        elif method == 'Stepwise':\n",
    "            stepwise_results, final_vars = stepwise_regression(X, y)\n",
    "            # Load the workbook if it exists, or initialize it\n",
    "            if os.path.exists(output_path):\n",
    "                workbook = load_workbook(output_path)\n",
    "                sheet_name = get_unique_sheet_name('Stepwise_Results', workbook)\n",
    "                if sheet_name in workbook.sheetnames:\n",
    "                    existing_data = pd.read_excel(output_path, sheet_name=sheet_name)\n",
    "                else:\n",
    "                    existing_data = pd.DataFrame()\n",
    "            else:\n",
    "                workbook = None\n",
    "                sheet_name = 'Stepwise_Results'\n",
    "                existing_data = pd.DataFrame()\n",
    "\n",
    "            try:\n",
    "                # Open the writer and write the data inside the with block\n",
    "                with pd.ExcelWriter(output_path, engine='openpyxl', mode='a' if os.path.exists(output_path) else 'w', if_sheet_exists=\"overlay\") as writer:\n",
    "                    if workbook:\n",
    "                        writer.book = workbook\n",
    "\n",
    "                    step_row = len(existing_data)  # Start after the existing data\n",
    "\n",
    "                    for step_name, result_df in stepwise_results:\n",
    "                        # Add a header for each step\n",
    "                        header_df = pd.DataFrame({step_name: ['']})\n",
    "                        header_df.to_excel(writer, sheet_name=sheet_name, startrow=step_row, index=False, header=False)\n",
    "                        step_row += 1\n",
    "\n",
    "                        # Write stepwise result DataFrame\n",
    "                        result_df.to_excel(writer, sheet_name=sheet_name, startrow=step_row, index=True)\n",
    "                        step_row += len(result_df) + 2  # Increment row for next step\n",
    "\n",
    "                    print(f\"Stepwise regression results saved to sheet: {sheet_name}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while saving results: {e}\")\n",
    "            \n",
    "\n",
    "# Attach the run_regression function to the button click\n",
    "button.on_click(run_regression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78eeca23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
